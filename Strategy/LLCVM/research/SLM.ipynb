{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Language Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. **Load** and **Process** news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nvidia nvda has solidified its position as a leader in the technology industry, especially within th'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '../data/dummy.txt'\n",
    "\n",
    "def process_raw_news(news):\n",
    "    news = news\\\n",
    "            .replace('\\n', '')\\\n",
    "            .lower()\n",
    "    return news\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    raw_news = process_raw_news(file.read())\n",
    "\n",
    "news = process_raw_news(raw_news)\n",
    "news[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. **Extract** vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(465,\n",
       " ['investors',\n",
       "  'maintaining',\n",
       "  'developers',\n",
       "  'infrastructure',\n",
       "  'blackwell',\n",
       "  'prospects',\n",
       "  'than',\n",
       "  'intelligence',\n",
       "  '135%',\n",
       "  'delivered'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = list(set(news.split(' ')))\n",
    "vocab_size = len(vocab)\n",
    "vocab_size, vocab[:10] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. **Build** *enconder* and *decoder*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = lambda ts: [vocab.index(t) for t in ts.split(' ')]\n",
    "decode = lambda il: ' '.join([vocab[i] for i in il])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([235,  54, 179, 205,  23,  24,  65, 429, 232, 241, 285, 164, 313,  92,\n",
       "        456, 285, 385, 435, 289, 459, 385, 304, 179, 458,  57,  65, 433,  65,\n",
       "        367, 134, 351, 413,  18, 275,  96, 436, 172, 125, 429, 168, 146, 460,\n",
       "        355, 285, 394, 242, 285, 305,   7, 452, 185, 381, 251, 179, 222, 172,\n",
       "        109, 414, 285, 249, 424, 269, 346, 411, 285, 374, 215, 237, 127, 339,\n",
       "         23, 167, 460, 319, 242, 405, 246, 235, 179, 285, 143, 342, 464, 429,\n",
       "        113, 146, 430, 456, 285,  13, 250, 172, 148,  23, 266, 241, 372, 443,\n",
       "        417, 226])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.tensor(encode(news), dtype=torch.long)\n",
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([235,  54, 179, 205,  23,  24,  65, 429, 232])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context:tensor([235]) -> target:54\n",
      "context:tensor([235,  54]) -> target:179\n",
      "context:tensor([235,  54, 179]) -> target:205\n",
      "context:tensor([235,  54, 179, 205]) -> target:23\n",
      "context:tensor([235,  54, 179, 205,  23]) -> target:24\n",
      "context:tensor([235,  54, 179, 205,  23,  24]) -> target:65\n",
      "context:tensor([235,  54, 179, 205,  23,  24,  65]) -> target:429\n",
      "context:tensor([235,  54, 179, 205,  23,  24,  65, 429]) -> target:232\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size + 1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target  = y[t]\n",
    "    print(f'context:{context} -> target:{target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "tensor([[264, 150, 323,  99, 401, 165,   0, 153],\n",
      "        [ 60,  59, 449, 417, 298, 241, 145, 398],\n",
      "        [ 17, 363, 357, 111, 416, 276, 241, 306],\n",
      "        [417, 298, 241, 145, 398,  42, 231, 401]])\n",
      "validate:\n",
      "tensor([[150, 323,  99, 401, 165,   0, 153, 342],\n",
      "        [ 59, 449, 417, 298, 241, 145, 398,  42],\n",
      "        [363, 357, 111, 416, 276, 241, 306, 242],\n",
      "        [298, 241, 145, 398,  42, 231, 401, 239]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix   = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x    = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y    = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train_data')\n",
    "print('train:')\n",
    "print(xb)\n",
    "print('validate:')\n",
    "print(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 465])\n",
      "tensor(6.6312, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "        \n",
    "        B, T, C = logits.shape\n",
    "        logits = logits.view(B*T, C)\n",
    "\n",
    "        targets = targets.view(B*T)\n",
    "\n",
    "        loss  = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "    \n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb,yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
